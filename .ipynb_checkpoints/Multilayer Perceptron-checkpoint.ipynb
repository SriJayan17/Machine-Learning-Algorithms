{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Multi_Layer_Perceptron:\n",
    "    \n",
    "    def __init__(self, lr):\n",
    "        \n",
    "        self.lr = lr\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        \n",
    "        return 1/(1+np.exp(-x))\n",
    "    \n",
    "    def update_outputlayer_weights(self):\n",
    "        \n",
    "        for i in range(self.output_weights.shape[0]):\n",
    "            \n",
    "            for j in range(self.output_weights.shape[1]):\n",
    "                \n",
    "                self.output_weights[i][j] += self.lr * self.outputs_errors[j] * self.hidden_outputs[i]\n",
    "            \n",
    "        \n",
    "    def update_hiddenlayer_weights(self):\n",
    "        \n",
    "        for i in range(self.hidden_weights.shape[0]):\n",
    "            \n",
    "            for j in range(self.hidden_weights.shape[1]):\n",
    "                \n",
    "                self.hidden_weights[i][j] += self.lr * self.hidden_errors[j] * self.inputs[i]\n",
    "    \n",
    "    def train(self, inputs,hidden,outputs,hidden_weights,output_weights,bias_input,bias_hidden_Weights,\n",
    "              bias_ouput_weights,iteration):\n",
    "        \n",
    "        self.inputs = inputs\n",
    "        self.outputs = outputs\n",
    "        self.predicted_outputs = np.array([0.0]*outputs.shape[0])\n",
    "        self.hidden_outputs = np.array([0.0] * hidden)\n",
    "        self.hidden_weights = hidden_weights\n",
    "        self.output_weights = output_weights\n",
    "        self.bias_input = bias_input\n",
    "        self.bias_hidden_Weights = bias_hidden_Weights\n",
    "        self.bias_ouput_weights = bias_ouput_weights\n",
    "        \n",
    "        count = 1\n",
    "        \n",
    "        while count <= iteration:\n",
    "            \n",
    "            self.outputs_errors = np.array([0.0] * outputs.shape[0])\n",
    "            self.hidden_errors = np.array([0.0] * hidden)\n",
    "            \n",
    "            for i in range(self.hidden_outputs.shape[0]):\n",
    "                \n",
    "                ipsum = np.sum(np.dot(self.inputs,self.hidden_weights[:,i:i+1])) + self.bias_input * self.bias_hidden_Weights[i]\n",
    "                self.hidden_outputs[i] = self.sigmoid(ipsum)\n",
    "            \n",
    "            for i in range(self.outputs.shape[0]):\n",
    "                \n",
    "                ipsum = np.sum(np.dot(self.hidden_outputs,self.output_weights[:,i:i+1])) + self.bias_input * self.bias_ouput_weights[i]\n",
    "                self.predicted_outputs[i] = self.sigmoid(ipsum)\n",
    "                \n",
    "                if self.predicted_outputs[i] != self.outputs[i]:\n",
    "                    \n",
    "                    self.outputs_errors[i] = self.predicted_outputs[i] * (1-self.predicted_outputs[i]) * (self.outputs[i] - self.predicted_outputs[i])\n",
    "            \n",
    "            for i in range(self.hidden_outputs.shape[0]):\n",
    "                \n",
    "                we = 0\n",
    "                \n",
    "                for j in range(self.outputs[0]):\n",
    "                    \n",
    "                    we += self.outputs_errors[j] * self.output_weights[i][j]\n",
    "                \n",
    "                self.hidden_errors[i] = self.hidden_outputs[i] * (1-self.hidden_outputs[i]) * we\n",
    "            \n",
    "            self.update_outputlayer_weights()\n",
    "            self.update_hiddenlayer_weights()\n",
    "            \n",
    "            print(f\"Hidden Layer Outputs : {self.hidden_outputs}\")\n",
    "            print(f\"Hidden Layer Errors : {self.hidden_errors}\")\n",
    "            print(f\"Output Layer Errors : {self.outputs_errors}\")\n",
    "            print(f\"Hidden Layer Weights : \\n{self.hidden_weights}\")\n",
    "            print(f\"Output Layer Weights : \\n{self.output_weights}\\n\\n\")\n",
    "            \n",
    "            count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.array([1,0,1])\n",
    "outputs = np.array([1])\n",
    "hidden_weights = np.array([[0.2,-0.3],[0.4,0.1],[-0.5,0.2]])\n",
    "output_weights = np.array([[-0.3],[-0.2]])\n",
    "bias_input = 1\n",
    "bias_hidden_weights = np.array([-0.4,0.2])\n",
    "bias_output_weights = np.array([0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_perceptron = Multi_Layer_Perceptron(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Outputs : [0.33181223 0.52497919]\n",
      "Hidden Layer Errors : [-0.00872456 -0.00654209]\n",
      "Output Layer Errors : [0.13116908]\n",
      "Hidden Layer Weights : \n",
      "[[ 0.19214789 -0.30588788]\n",
      " [ 0.4         0.1       ]\n",
      " [-0.50785211  0.19411212]]\n",
      "Output Layer Weights : \n",
      "[[-0.26082885]\n",
      " [-0.13802507]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ml_perceptron.train(inputs,2,outputs,hidden_weights,output_weights,bias_input,bias_hidden_weights,bias_output_weights,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
